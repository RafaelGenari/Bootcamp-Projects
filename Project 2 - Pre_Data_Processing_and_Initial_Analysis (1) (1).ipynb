{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0vqbgi9ay0H"
   },
   "source": [
    "# Get into the music / Se liga na música"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhq_eyov_Zcs"
   },
   "source": [
    "# Content <a id='back'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [Step 1: Data overview](#data_review)\n",
    "    * [Conclusions](#data_review_conclusions)\n",
    "* [Step 2: Data preprocessing](#data_preprocessing)\n",
    "    * [2.1 Header style](#header_style)\n",
    "    * [2.2 Missing values](#missing_values)\n",
    "    * [2.3 Duplicates](#duplicates)\n",
    "    * [2.4 Conclusions](#data_preprocessing_conclusions)\n",
    "* [Step 3. Hypothesis testing](#hypothesis)\n",
    "    * [3.1 Hypothesis 1: user activity in the two cities](#activity)\n",
    "* [Conclusions](#end)\n",
    "\n",
    "=========================================================================================================================\n",
    "\n",
    "# Conteúdo <a id='back'></a>\n",
    "\n",
    "* [Introdução](#intro)\n",
    "* [Etapa 1. Visão geral dos dados](#data_review)\n",
    "    * [Conclusões](#data_review_conclusions)\n",
    "* [Etapa 2. Pré-processamento de dados](#data_preprocessing)\n",
    "    * [2.1 Estilo do cabeçalho](#header_style)\n",
    "    * [2.2 Valores ausentes](#missing_values)\n",
    "    * [2.3 Duplicados](#duplicates)\n",
    "    * [2.4 Conclusões](#data_preprocessing_conclusions)\n",
    "* [Etapa 3. Teste da hipótese](#hypothesis)\n",
    "    * [3.1 Hipótese 1: atividade dos usuários nas duas cidades](#activity)\n",
    "* [Conclusões](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUC88oWjTJw2"
   },
   "source": [
    "## Introduction <a id='intro'></a>\n",
    "An analyst's job is to analyze data in order to gain valuable insights from the data and make decisions based on them. This process consists of several steps, such as data overview, data pre-processing and hypothesis testing.\n",
    "\n",
    "Whenever we do research, we need to formulate a hypothesis that we can then test. Sometimes we accept these hypotheses; sometimes we reject them. To make the right choices, a business must be able to understand whether it is making the right assumptions or not.\n",
    "\n",
    "In this project, you will compare the musical preferences of the inhabitants of Springfild and Shelbyville. You will study data from an online music streaming service to test the hypothesis presented below and compare the behavior of users in these two cities.\n",
    "\n",
    "### Objective:\n",
    "Test the hypothesis:\n",
    "1. User activity is different depending on the day of the week and the city.\n",
    "\n",
    "\n",
    "### Steps\n",
    "The data on user behavior is stored in the file `/datasets/music_project_en.csv`. There is no information on the quality of the data, so it will be necessary to examine it before testing the hypothesis.\n",
    "\n",
    "First, you will assess the quality of the data and see if your problems are significant. Then, during data pre-processing, you will try to address the most critical problems.\n",
    "\n",
    "Your project will consist of three stages:\n",
    " 1. Data overview\n",
    " 2. Data pre-processing\n",
    " 3. Hypothesis testing\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Introdução`\n",
    "\n",
    "O trabalho de um analista é analisar dados para obter percepções valiosas dos dados e tomar decisões fundamentadas neles. Esse processo consiste em várias etapas, como visão geral dos dados, pré-processamento dos dados e testes de hipóteses.\n",
    "\n",
    "Sempre que fazemos uma pesquisa, precisamos formular uma hipótese que depois poderemos testar. Às vezes nós aceitamos essas hipóteses; outras vezes, nós as rejeitamos. Para fazer as escolhas certas, um negócio deve ser capaz de entender se está fazendo as suposições certas ou não.\n",
    "\n",
    "Neste projeto, você vai comparar as preferências musicais dos habitantes de Springfild e Shelbyville. Você vai estudar os dados de um serviço de streaming de música online para testar a hipótese apresentada abaixo e comparar o comportamento dos usuários dessas duas cidades.\n",
    "\n",
    "`Objetivo:`\n",
    "Teste a hipótese:\n",
    "1. A atividade dos usuários é diferente dependendo do dia da semana e da cidade.\n",
    "\n",
    "\n",
    "`Etapas:`\n",
    "Os dados sobre o comportamento do usuário são armazenados no arquivo `/datasets/music_project_en.csv`. Não há informações sobre a qualidade dos dados, então será necessário examiná-los antes de testar a hipótese.\n",
    "\n",
    "Primeiro, você avaliará a qualidade dos dados e verá se seus problemas são significativos. Depois, durante o pré-processamento dos dados, você tentará tratar dos problemas mais críticos.\n",
    "\n",
    "O seu projeto consistirá em três etapas:\n",
    " 1. Visão geral dos dados\n",
    " 2. Pré-processamento de dados\n",
    " 3. Teste da hipótese\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDt6pg-Rw-1U"
   },
   "source": [
    "[Back to Index](#back)\n",
    "\n",
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml1hmfXC_Zcs"
   },
   "source": [
    "## Step 1. Data overview <a id='data_review'></a>\n",
    "\n",
    "Open the data and examine it.\n",
    "\n",
    "Abra os dados e examine-os."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57eAOGIz_Zcs"
   },
   "source": [
    "You'll need `pandas`, so import it.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Você precisará da `pandas`, então, importe-a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AXN7PHPN_Zcs"
   },
   "outputs": [],
   "source": [
    "# importing pandas / importando pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG23P8tt_Zcs"
   },
   "source": [
    "Read the file `music_project_en.csv` from the `/datasets/` folder and save it in the variable `df`:\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Leia o arquivo `music_project_en.csv` da pasta `/datasets/` e salve-o na variável `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fFVu7vqh_Zct"
   },
   "outputs": [],
   "source": [
    "# reading the file and storing it in df / lendo o arquivo e armazenando em df\n",
    "\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDoOMd3uTqnZ"
   },
   "source": [
    "Print the first 10 rows of the table:\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Imprima as primeiras 10 linhas da tabela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oWTVX3gW_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>Track</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>City</th>\n",
       "      <th>time</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFB692EC</td>\n",
       "      <td>Kamigata To Boots</td>\n",
       "      <td>The Mass Missile</td>\n",
       "      <td>rock</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:28:33</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55204538</td>\n",
       "      <td>Delayed Because of Accident</td>\n",
       "      <td>Andreas Rönnberg</td>\n",
       "      <td>rock</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>14:07:09</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20EC38</td>\n",
       "      <td>Funiculì funiculà</td>\n",
       "      <td>Mario Lanza</td>\n",
       "      <td>pop</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:58:07</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3DD03C9</td>\n",
       "      <td>Dragons in the Sunset</td>\n",
       "      <td>Fire + Ice</td>\n",
       "      <td>folk</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>08:37:09</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2DC1FAE</td>\n",
       "      <td>Soul People</td>\n",
       "      <td>Space Echo</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>08:34:34</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>842029A1</td>\n",
       "      <td>Chains</td>\n",
       "      <td>Obladaet</td>\n",
       "      <td>rusrap</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>13:09:41</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4CB90AA5</td>\n",
       "      <td>True</td>\n",
       "      <td>Roman Messer</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>13:00:07</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F03E1C1F</td>\n",
       "      <td>Feeling This Way</td>\n",
       "      <td>Polina Griffith</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>20:47:49</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8FA1D3BE</td>\n",
       "      <td>L’estate</td>\n",
       "      <td>Julia Dalia</td>\n",
       "      <td>ruspop</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>09:17:40</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E772D5C0</td>\n",
       "      <td>Pessimist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dance</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>21:20:49</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID                        Track            artist   genre  \\\n",
       "0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n",
       "1  55204538  Delayed Because of Accident  Andreas Rönnberg    rock   \n",
       "2    20EC38            Funiculì funiculà       Mario Lanza     pop   \n",
       "3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n",
       "4  E2DC1FAE                  Soul People        Space Echo   dance   \n",
       "5  842029A1                       Chains          Obladaet  rusrap   \n",
       "6  4CB90AA5                         True      Roman Messer   dance   \n",
       "7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n",
       "8  8FA1D3BE                     L’estate       Julia Dalia  ruspop   \n",
       "9  E772D5C0                    Pessimist               NaN   dance   \n",
       "\n",
       "        City        time        Day  \n",
       "0  Shelbyville  20:28:33  Wednesday  \n",
       "1  Springfield  14:07:09     Friday  \n",
       "2  Shelbyville  20:58:07  Wednesday  \n",
       "3  Shelbyville  08:37:09     Monday  \n",
       "4  Springfield  08:34:34     Monday  \n",
       "5  Shelbyville  13:09:41     Friday  \n",
       "6  Springfield  13:00:07  Wednesday  \n",
       "7  Springfield  20:47:49  Wednesday  \n",
       "8  Springfield  09:17:40     Friday  \n",
       "9  Shelbyville  21:20:49  Wednesday  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first 10 rows of the df table / obtenha as 10 primeiras 10 linhas da tabela df\n",
    "\n",
    "df.head(10) # if we didn't use the number 10 in the parentheses, we would only print the first 5 rows / se não fosse utilizado o número 10 no parênteses, seriam impressos apenas as 5 primeiras linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO73Kwic_Zct"
   },
   "source": [
    "Get general information about the table using a command. You know the method for displaying the general information we need.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Obtenha informações gerais sobre a tabela usando um comando. Você conhece o método para exibir informações gerais que precisamos obter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DSf2kIb-_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65079 entries, 0 to 65078\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0     userID  65079 non-null  object\n",
      " 1   Track     63736 non-null  object\n",
      " 2   artist    57512 non-null  object\n",
      " 3   genre     63881 non-null  object\n",
      " 4     City    65079 non-null  object\n",
      " 5   time      65079 non-null  object\n",
      " 6   Day       65079 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.5+ MB\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  userID       0\n",
       "Track       1343\n",
       "artist      7567\n",
       "genre       1198\n",
       "  City         0\n",
       "time           0\n",
       "Day            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting general information about our data / obtendo informações gerais sobre os nossos dados\n",
    "\n",
    "df.info() # to have information about the dataframe such as index, existing columns, null/missing values, type, among others. / para ter informações sobre o dataframe como index, colunas existentes, valores nulos/ausentes, tipo, entre outras.\n",
    "print() # empty line to have a space between the results of the lines of code / linha vazia para ter um espaço entre os resultados das linhas de código\n",
    "df.duplicated().sum() # to find out if there are duplicate values / descobrir se existe valores duplicados\n",
    "print()\n",
    "df.isna().sum() # sum the null/absent values of each column / soma dos valores nulos/ausentes de cada coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQ2Iwbr_Zct"
   },
   "source": [
    "Here are our observations on the table. It contains seven columns. They store the same data type: `object`.\n",
    "\n",
    "According to the documentation:\n",
    "- `' userID'` - user ID\n",
    "- `'Track'` - song title\n",
    "- `'artist'` - artist name\n",
    "- `'genre'` - genre of the song\n",
    "- `'City'` - user's city\n",
    "- `'time'` - the exact time the song was played\n",
    "- `'Day'` - day of the week\n",
    "\n",
    "We can see three style problems in the table headers:\n",
    "1. Some headings are written in capital letters, others in lower case.\n",
    "2. Some headers contain spaces.\n",
    "3. `Detect the problem and describe it here` - When printing df.info() we see information from the dataframe in which it is possible to identify that there is a difference in how the columns are written, in which some start with capital letters and others don't, as well as that two columns, 0 - userID and 4 - City, have spacing before writing.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Aqui estão as nossas observações sobre a tabela. Ela contém sete colunas. Elas armazenam o mesmo tipo de dado: `object`.\n",
    "\n",
    "De acordo com a documentação:\n",
    "- `' userID'` — identificação do usuário\n",
    "- `'Track'` — título da música\n",
    "- `'artist'` — nome do artista\n",
    "- `'genre'` — gênero da música\n",
    "- `'City'` — cidade do usuário\n",
    "- `'time'` — o tempo exato que a música foi reproduzida\n",
    "- `'Day'` — dia da semana\n",
    "\n",
    "Podemos ver três problemas de estilo nos cabeçalhos da tabela:\n",
    "1. Alguns cabeçalhos são escritos em letras maiúsculas, outros estão em minúsculas.\n",
    "2. Alguns cabeçalhos contêm espaços.\n",
    "3. `Detecte o problema e o descreva aqui` - Ao imprimir df.info() vemos informações do dataframe em que é possível identificar que existe uma diferença em como estão escritas as colunas, em que algumas começam com letra maiúsculas e outras não, bem como que duas colunas, a 0 - userID e 4 - City, estão com espaçamento antes da escrita.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCB6-dXG_Zct"
   },
   "source": [
    "### Write down your observations. Here are some questions that might help: <a id='data_review_conclusions'></a>\n",
    "\n",
    "`1.   What kind of data do we have in the rows? And how can we understand the columns?`\n",
    "        - In the rows we have information that corresponds to the name of the column, but we also have missing values in all of them. In the rows we will see information such as the user's ID, the song they listened to, the artist, the genre, the user's city, the playing time and the day of the week they listened to the song. At this early stage, we can understand the columns by looking at the title that has been defined for them and understanding the information that will be displayed, for example, the 'Track' column will contain data corresponding to the name of the song listened to.\n",
    "\n",
    "`2.   Is this data enough to answer our hypothesis or do we need more data?`\n",
    "        - This data may be enough to answer our hypothesis, but we can only be sure of this once we have cleaned the data and analyzed it, so we will see if we can answer our hypothesis or if we need more data.\n",
    "\n",
    "`3.   Have you noticed any problems with the data, such as missing values, duplicates or wrong data types?`\n",
    "        - Based on this initial check, we were able to verify missing and duplicate values, as well as the data type, however, with these initial checks alone, we cannot conclude whether there are significant problems in the data without pre-processing and a more detailed analysis.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Escreva suas observações. Aqui estão algumas perguntas que podem ajudar:`\n",
    "\n",
    "`1.   Que tipo de dados temos nas linhas? E como podemos entender as colunas?`\n",
    "        - Nas linhas temos informações que correspondem ao nome da coluna, contudo, também temos valores ausentes em todas elas. Nas linhas iremos ver informações como identificação do usuário, a música ouvida, qual o artista, o gênero, qual a Cidade do usuário, o tempo de reprodução e o dia da semana em que ouviu a música. Nesta fase inicial podemos entender as colunas ao olhar para o título que foi definido para ela e compreendermos a informação que será aprensentada, como por exemplo, a coluna 'Track' serão dados correspondentes ao nome da música ouvida\n",
    "\n",
    "`2.   Esses dados são suficientes para responder à nossa hipótese ou precisamos de mais dados?`\n",
    "        - Estes dados poderão ser o suficiente para responder a nossa hipótese, mas apenas será possível uma certeza disso após ser feita toda a limpeza dos dados e análise dos mesmo, de modo que veremos perceberemos se conseguimos responder a nossa hipótese ou se precisaremos de mais dados.\n",
    "\n",
    "`3.   Você notou algum problema nos dados, como valores ausentes, duplicados ou tipos de dados errados`\n",
    "        - Com base nesta verificação inicial conseguimos verificar valores ausentes e duplicados, bem como o tipo de dados, no entanto, apenas com essas verificações iniciais, não podemos concluir se há problemas significativos nos dados sem um pré-processamento e uma análise mais detalhada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDt6pg-Rw-1U"
   },
   "source": [
    "[Back to Index](#back)\n",
    "\n",
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjYF6Ub9_Zct"
   },
   "source": [
    "## Step 2. Data pre-processing <a id='data_preprocessing'></a>\n",
    "\n",
    "The aim here is to prepare the data for analysis.\n",
    "The first step is to resolve any problems with the header. Then we can move on to missing and duplicate values. Let's get started.\n",
    "\n",
    "Correct the formatting in the table headers\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Etapa 2. Pré-processamento de dados`\n",
    "\n",
    "O objetivo aqui é preparar os dados para a análise.\n",
    "O primeiro passo é resolver todos os problemas com o cabeçalho. E então podemos passar para os valores ausentes e duplicados. Vamos começar.\n",
    "\n",
    "Corrija a formatação nos cabeçalhos da tabela.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaKXr29_Zct"
   },
   "source": [
    "### Header style <a id='header_style'></a>\n",
    "Print the table headers (the column names):\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Cabeçalho`\n",
    "\n",
    "Imprima os cabeçalhos da tabela (os nomes das colunas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oKOTdF_Q_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print the column names / imprima os nomes das colunas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj5534cv_Zct"
   },
   "source": [
    "Change the table headers according to good style practices:\n",
    "* All characters must be lowercase\n",
    "* Exclude spaces\n",
    "* If the name contains several words, use snake_case\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Mude os cabeçalhos da tabela conforme as boas práticas de estilo:\n",
    "* Todos os caracteres precisam estar com letras minúsculas\n",
    "* Exclua espaços\n",
    "* Se o nome tiver várias palavras, use snake_case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu0zkfe5zNJe"
   },
   "source": [
    "Earlier, you learned about an automated way of renaming columns. Let's use it now. Use the for loop to go through the column names and turn all the characters into lowercase letters. After doing this, print the table headers again:\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Anteriormente, você aprendeu sobre uma maneira automatizada de renomear colunas. Vamos usá-la agora. Use o ciclo for para percorrer os nomes das colunas e transformar todos os caracteres em letras minúsculas. Após fazer isso, imprima os cabeçalhos da tabela novamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6I_RwwMhzM4e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['  userid', 'track', 'artist', 'genre', '  city  ', 'time', 'day'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrolling through the headers and converting everything to lowercase / percorrendo os cabeçalhos e convertendo tudo em minúsculos\n",
    "\n",
    "header = ['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day']\n",
    "header_low = []\n",
    "\n",
    "for data in header: # loop to check list data / ciclo for para verificar dados da lista\n",
    "    header_low.append(data.lower()) # transforms data to lowercase / transforma os dados para letras minúsculas\n",
    "    \n",
    "df.columns = header_low\n",
    "    \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pweIRxjSzPYW"
   },
   "source": [
    "Now, using the same approach, delete the spaces at the beginning and end of each column name and print the column names again:\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Agora, usando a mesma abordagem, exclua os espaços no início e no final de cada nome de coluna e imprima os nomes das colunas novamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vVQXbFyJzSYl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrolling through headers and removing spaces / percorrendo os cabeçalhos e removendo os espaços\n",
    "\n",
    "header_no_space = []\n",
    "\n",
    "for spaces in header_low:\n",
    "    header_no_space.append(spaces.strip()) # removes spaces at the beginning and end / remove espaços existentes no início e no final\n",
    "\n",
    "df.columns = header_no_space\n",
    "    \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCb8MW1JzURd"
   },
   "source": [
    "We need to apply the underscore instead of space rule to the `userid` column. It should be `user_id`. Rename this column and print the names of all the columns when you're done.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Precisamos aplicar a regra de sublinhado no lugar de espaço à coluna `userid`. Deveria ser `user_id`. Renomeie essa coluna e imprima os nomes de todas as colunas quando terminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ISlFqs5y_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# renaming the “userid” column / renomeando a coluna \"userid\"\n",
    "\n",
    "header_new ={\n",
    "    'userid' : 'user_id',\n",
    "}\n",
    "\n",
    "df.rename(columns = header_new, inplace = True)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dqbh00J_Zct"
   },
   "source": [
    "Check the result. Print the headers again:\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Verifique o resultado. Imprima os cabeçalhos novamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d4NOAmTW_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the result: the list of headers / verificando o resultado: a lista de cabeçalhos\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYJk6ksJVpOl"
   },
   "source": [
    "[Back to Index](#back)\n",
    "\n",
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ISfbcfY_Zct"
   },
   "source": [
    "### Missing values <a id='missing_values'></a>\n",
    " First, find the number of missing values in the table. You need to use two methods in sequence to get the number of missing values.\n",
    " \n",
    "==============================================================\n",
    "\n",
    "`Valores Ausentes`\n",
    "\n",
    "Primeiro, encontre a quantidade de valores ausentes na tabela. Você precisa usar dois métodos em sequência para obter o número de valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RskX29qr_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id       0\n",
       "track      1343\n",
       "artist     7567\n",
       "genre      1198\n",
       "city          0\n",
       "time          0\n",
       "day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the number of missing values / calculando o número de valores ausentes\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qubhgnlO_Zct"
   },
   "source": [
    "Not all missing values affect the search. For example, the missing values in `track` and `artist` are not critical. You can simply replace them with default values, such as the string `'unknown'`.\n",
    "\n",
    "But missing values in `'genre'` could affect the comparison of Springfield and Shelbyville's musical preferences. In real life, it would be useful to find out why the data is missing and try to correct it. But we don't have that possibility in this project. So you'll have to:\n",
    "* Fill in these missing values with a default value\n",
    "* Evaluate the extent to which missing values can affect your analysis\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Nem todos os valores ausentes afetam a pesquisa. Por exemplo, os valores ausentes em `track` e `artist` não são críticos. Você pode simplesmente substituí-los por valores padrão, como a string `'unknown'`.\n",
    "\n",
    "Mas valores ausentes em `'genre'` podem afetar a comparação de preferências musicais de Springfield e Shelbyville. Na vida real, seria útil descobrir as razões pelas quais os dados estão ausentes e tentar corrigi-los. Mas nós não temos essa possibilidade neste projeto. Então, você terá que:\n",
    "* Preencha esses valores ausentes com um valor padrão\n",
    "* Avalie em que medida os valores ausentes podem afetar sua análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSv2laPA_Zct"
   },
   "source": [
    "Replace the missing values in the `'track'`, `'artist'` and `'genre'` columns with the string `'unknown'`. As we've shown in previous lessons, the best way to do this is to create a list to store the names of the columns in which we need to make the substitution. Then use this list and go through the columns where the substitution is needed and make the substitution.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Substitua os valores ausentes nas colunas `'track'`, `'artist'` e `'genre'` pela string `'unknown'`. Como mostramos nas lições anteriores, a melhor maneira de fazer isso é criar uma lista para armazenar os nomes das colunas nas quais precisamos fazer a substituição. Em seguida, use essa lista e percorra as colunas nas quais a substituição seja necessária e faça a substituição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KplB5qWs_Zct"
   },
   "outputs": [],
   "source": [
    "# going through the headers and replacing missing values with 'unknown' / percorrendo os cabeçalhos e substituindo valores ausentes por 'unknown'\n",
    "\n",
    "columns_to_replace = ['track', 'artist', 'genre'] # columns to be changed / colunas a serem alteradas\n",
    "\n",
    "for data in columns_to_replace: # loop to check columns and change missing values to 'unknown' / ciclo for para checar colunas e alterar vcalores ausentes por 'unknown'\n",
    "    df[data].fillna('unknown', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilsm-MZo_Zct"
   },
   "source": [
    "Now check the result to make sure that the data set doesn't contain any missing values after the replacement. To do this, count the missing values again.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Agora verifique o resultado para ter certeza de que o conjunto de dados não contenha valores ausentes após a substituição. Para fazer isso, conte os valores ausentes novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Tq4nYRX4_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    0\n",
       "track      0\n",
       "artist     0\n",
       "genre      0\n",
       "city       0\n",
       "time       0\n",
       "day        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the missing values / contando os valores ausentes\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ZIBmq9VrsK"
   },
   "source": [
    "[Back to Index](#back)\n",
    "\n",
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWKRtBJ3_Zct"
   },
   "source": [
    "### Duplicates <a id='duplicates'></a>\n",
    "Find the number of explicit duplicates in the table. Remember that you need to apply two methods in sequence to get the number of explicit duplicates.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Duplicados`\n",
    "\n",
    "Encontre o número de duplicados explícitos na tabela. Lembre-se de que você precisa aplicar dois métodos em sequência para obter o número de duplicados explícitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "36eES_S0_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3826"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting explicit duplicates / contando duplicados explícitos\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot25h6XR_Zct"
   },
   "source": [
    "Now discard all duplicates. To do this, call the method that does just that.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Agora descarte todos os duplicados. Para fazer isso, chame o método que faz exatamente isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "exFHq6tt_Zct"
   },
   "outputs": [],
   "source": [
    "# removing explicit duplicates / removendo duplicados explícitos\n",
    "\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im2YwBEG_Zct"
   },
   "source": [
    "Now let's check that we've discarded all duplicates. Count explicit duplicates one more time to make sure you've removed all of them:\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Agora vamos verificar se descartamos todos os duplicados. Conte duplicados explícitos mais uma vez para ter certeza de que você removeu todos eles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-8PuNWQ0_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking duplicates again / verificando duplicados novamente\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlFBsxAr_Zct"
   },
   "source": [
    "Now we want to get rid of the implicit duplicates in the `genre` column. For example, the name of a gender can be written in different ways. Some errors will also affect the result.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Agora queremos nos livrar dos duplicados implícitos na coluna `genre`. Por exemplo, o nome de um gênero pode ser escrito de maneiras diferentes. Alguns erros afetarão também o resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSjWwsOh_Zct"
   },
   "source": [
    "To do this, let's start by printing a list of unique gender names, sorted in alphabetical order: To do this:\n",
    "* Extract the `genre` column from the DataFrame\n",
    "* Call the method that will return all the unique values in the extracted column\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Para fazer isso, vamos começar imprimindo uma lista de nomes de gênero únicos, ordenados em ordem alfabética: Para fazer isso:\n",
    "* Extraia a coluna `genre` do DataFrame\n",
    "* Chame o método que retornará todos os valores únicos na coluna extraída\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JIUcqzZN_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n",
      " 'unknown' 'alternative' 'children' 'rnb' 'hip' 'jazz' 'postrock' 'latin'\n",
      " 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n",
      " 'dnb' 'türk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'hiphop' 'drum' 'extrememetal' 'türkçe'\n",
      " 'experimental' 'easy' 'metalcore' 'modern' 'argentinetango' 'old' 'swing'\n",
      " 'breaks' 'eurofolk' 'stonerrock' 'industrial' 'funk' 'middle' 'variété'\n",
      " 'other' 'adult' 'christian' 'thrash' 'gothic' 'international' 'muslim'\n",
      " 'relax' 'schlager' 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage'\n",
      " 'specialty' 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power'\n",
      " 'death' 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european'\n",
      " 'tech' 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera'\n",
      " 'celtic' 'tradjazz' 'acoustic' 'epicmetal' 'hip-hop' 'historisch'\n",
      " 'downbeat' 'downtempo' 'africa' 'audiobook' 'jewish' 'sängerportrait'\n",
      " 'deutschrock' 'eastern' 'action' 'future' 'electropop' 'folklore'\n",
      " 'bollywood' 'marschmusik' 'rnr' 'karaoke' 'indian' 'rancheras'\n",
      " 'afrikaans' 'rhythm' 'sound' 'deutschspr' 'trip' 'lovers' 'choral'\n",
      " 'dancepop' 'retro' 'smooth' 'mexican' 'brazilian' 'ïîï' 'mood' 'surf'\n",
      " 'gangsta' 'inspirational' 'idm' 'ethnic' 'bluegrass' 'broadway'\n",
      " 'animated' 'americana' 'karadeniz' 'rockabilly' 'colombian' 'self' 'hop'\n",
      " 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport' 'ragga' 'traditional'\n",
      " 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop' 'glitch' 'documentary'\n",
      " 'oceania' 'popeurodance' 'dark' 'vi' 'grunge' 'hardstyle' 'samba'\n",
      " 'garage' 'art' 'folktronica' 'entehno' 'mediterranean' 'chamber' 'cuban'\n",
      " 'taraftar' 'gypsy' 'hardtechno' 'shoegazing' 'bossa' 'latino' 'worldbeat'\n",
      " 'malaysian' 'baile' 'ghazal' 'arabic' 'popelectronic' 'acid' 'kayokyoku'\n",
      " 'neoklassik' 'tribal' 'tanzorchester' 'native' 'independent' 'cantautori'\n",
      " 'handsup' 'punjabi' 'synthpop' 'rave' 'französisch' 'quebecois' 'speech'\n",
      " 'soulful' 'jam' 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow'\n",
      " 'jungle' 'indipop' 'axé' 'fado' 'showtunes' 'arena' 'irish' 'mandopop'\n",
      " 'forró' 'dirty' 'regional']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "269"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing unique genre names / visualizando nomes de gêneros únicos\n",
    "\n",
    "print(df['genre'].unique())\n",
    "print()\n",
    "df['genre'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qej-Qmuo_Zct"
   },
   "source": [
    "Look through the list and find implicit duplicates of the genre `hiphop`. These could be misspelled names, or alternative names for the same genre.\n",
    "\n",
    "You will see the following implicit duplicates:\n",
    "* `hip`\n",
    "* `hop`\n",
    "* `hip-hop`\n",
    "\n",
    "To get rid of them, create a `replace_wrong_genres()` function with two parameters:\n",
    "* `wrong_genres=` - this is a list containing all the values you need to replace\n",
    "* `correct_genre=` - this is a string that you will use for the replacement\n",
    "\n",
    "As a result, the function should correct the names in the `'genre'` column of the `df` table, i.e. by replacing each value in the `wrong_genres` list with values from `correct_genre`.\n",
    "\n",
    "Inside the function body, use a `'for'` loop to go through the list of wrong genres, extract the `'genre'` column and apply the `replace` method to make the corrections.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Olhe a lista e encontre duplicados implícitos do gênero `hiphop`. Esses podem ser nomes escritos incorretamente, ou nomes alternativos para o mesmo gênero.\n",
    "\n",
    "Você verá os seguintes duplicados implícitos:\n",
    "* `hip`\n",
    "* `hop`\n",
    "* `hip-hop`\n",
    "\n",
    "Para se livrar deles, crie uma função `replace_wrong_genres()` com dois parâmetros:\n",
    "* `wrong_genres=` — essa é uma lista que contém todos os valores que você precisa substituir\n",
    "* `correct_genre=` — essa é uma string que você vai usar para a substituição\n",
    "\n",
    "Como resultado, a função deve corrigir os nomes na coluna `'genre'` da tabela `df`, isto é, substituindo cada valor da lista `wrong_genres` por valores de `correct_genre`.\n",
    "\n",
    "Dentro do corpo da função, use um ciclo `'for'` para percorrer a lista de gêneros errados, extrair a coluna `'genre'` e aplicar o método `replace` para fazer as correções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ErNDkmns_Zct"
   },
   "outputs": [],
   "source": [
    "# function to replace implicit duplicates / função para substituir duplicados implícitos\n",
    "\n",
    "def replace_wrong_genres(df, column, wrong_genres, correct_genre):\n",
    "    for wrong_genres in wrong_genres:\n",
    "        df['genre'] = df['genre'].replace(wrong_genres, correct_genre)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoBJxbA_Zct"
   },
   "source": [
    "Now, call the `replace_wrong_genres()` function and pass appropriate arguments so that it cleans up implicit duplicates (`hip`, `hop` and `hip-hop`) by replacing them with `hiphop`:\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Agora, chame a função `replace_wrong_genres()` e passe argumentos apropriados para que ela limpe duplicados implícitos (`hip`, `hop` e `hip-hop`) substituindo-os por `hiphop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YN5i2hpmSo09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>track</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>city</th>\n",
       "      <th>time</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFB692EC</td>\n",
       "      <td>Kamigata To Boots</td>\n",
       "      <td>The Mass Missile</td>\n",
       "      <td>rock</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:28:33</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55204538</td>\n",
       "      <td>Delayed Because of Accident</td>\n",
       "      <td>Andreas Rönnberg</td>\n",
       "      <td>rock</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>14:07:09</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20EC38</td>\n",
       "      <td>Funiculì funiculà</td>\n",
       "      <td>Mario Lanza</td>\n",
       "      <td>pop</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:58:07</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3DD03C9</td>\n",
       "      <td>Dragons in the Sunset</td>\n",
       "      <td>Fire + Ice</td>\n",
       "      <td>folk</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>08:37:09</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2DC1FAE</td>\n",
       "      <td>Soul People</td>\n",
       "      <td>Space Echo</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>08:34:34</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65074</th>\n",
       "      <td>729CBB09</td>\n",
       "      <td>My Name</td>\n",
       "      <td>McLean</td>\n",
       "      <td>rnb</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>13:32:28</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65075</th>\n",
       "      <td>D08D4A55</td>\n",
       "      <td>Maybe One Day (feat. Black Spade)</td>\n",
       "      <td>Blu &amp; Exile</td>\n",
       "      <td>hiphop</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65076</th>\n",
       "      <td>C5E3A0D5</td>\n",
       "      <td>Jalopiina</td>\n",
       "      <td>unknown</td>\n",
       "      <td>industrial</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>20:09:26</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65077</th>\n",
       "      <td>321D0506</td>\n",
       "      <td>Freight Train</td>\n",
       "      <td>Chas McDevitt</td>\n",
       "      <td>rock</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>21:43:59</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65078</th>\n",
       "      <td>3A64EF84</td>\n",
       "      <td>Tell Me Sweet Little Lies</td>\n",
       "      <td>Monica Lopez</td>\n",
       "      <td>country</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>21:59:46</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61253 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                              track            artist  \\\n",
       "0      FFB692EC                  Kamigata To Boots  The Mass Missile   \n",
       "1      55204538        Delayed Because of Accident  Andreas Rönnberg   \n",
       "2        20EC38                  Funiculì funiculà       Mario Lanza   \n",
       "3      A3DD03C9              Dragons in the Sunset        Fire + Ice   \n",
       "4      E2DC1FAE                        Soul People        Space Echo   \n",
       "...         ...                                ...               ...   \n",
       "65074  729CBB09                            My Name            McLean   \n",
       "65075  D08D4A55  Maybe One Day (feat. Black Spade)       Blu & Exile   \n",
       "65076  C5E3A0D5                          Jalopiina           unknown   \n",
       "65077  321D0506                      Freight Train     Chas McDevitt   \n",
       "65078  3A64EF84          Tell Me Sweet Little Lies      Monica Lopez   \n",
       "\n",
       "            genre         city      time        day  \n",
       "0            rock  Shelbyville  20:28:33  Wednesday  \n",
       "1            rock  Springfield  14:07:09     Friday  \n",
       "2             pop  Shelbyville  20:58:07  Wednesday  \n",
       "3            folk  Shelbyville  08:37:09     Monday  \n",
       "4           dance  Springfield  08:34:34     Monday  \n",
       "...           ...          ...       ...        ...  \n",
       "65074         rnb  Springfield  13:32:28  Wednesday  \n",
       "65075      hiphop  Shelbyville  10:00:00     Monday  \n",
       "65076  industrial  Springfield  20:09:26     Friday  \n",
       "65077        rock  Springfield  21:43:59     Friday  \n",
       "65078     country  Springfield  21:59:46     Friday  \n",
       "\n",
       "[61253 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing implicit duplicates / removendo duplicados implícitos\n",
    "\n",
    "old_genres = ['hip', 'hop', 'hip-hop']\n",
    "new_genre = 'hiphop'\n",
    "\n",
    "replace_wrong_genres(df, 'genre', old_genres, new_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQKF16_RG15m"
   },
   "source": [
    "Make sure that duplicate names have been removed. Print the list of unique values from the `'genre'` column once again:\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Certifique-se que os nomes duplicados foram removidos. Imprima a lista de valores únicos da coluna `'genre'` mais uma vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "wvixALnFG15m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n",
      " 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n",
      " 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n",
      " 'rusrock' 'dnb' 'türk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'drum' 'extrememetal' 'türkçe' 'experimental' 'easy'\n",
      " 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n",
      " 'stonerrock' 'industrial' 'funk' 'middle' 'variété' 'other' 'adult'\n",
      " 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n",
      " 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n",
      " 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n",
      " 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n",
      " 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n",
      " 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n",
      " 'africa' 'audiobook' 'jewish' 'sängerportrait' 'deutschrock' 'eastern'\n",
      " 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n",
      " 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n",
      " 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n",
      " 'brazilian' 'ïîï' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n",
      " 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n",
      " 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n",
      " 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n",
      " 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n",
      " 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n",
      " 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n",
      " 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n",
      " 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n",
      " 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n",
      " 'synthpop' 'rave' 'französisch' 'quebecois' 'speech' 'soulful' 'jam'\n",
      " 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n",
      " 'axé' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forró' 'dirty'\n",
      " 'regional']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicate values / verificando valores duplicados\n",
    "\n",
    "print(df['genre'].unique())\n",
    "print()\n",
    "df['genre'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALgNbvF3VtPA"
   },
   "source": [
    "[Back to Index](#back)\n",
    "\n",
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz6a9-7HQUDd"
   },
   "source": [
    "### Your observations <a id='data_preprocessing_conclusions'></a>\n",
    "\n",
    "` Briefly describe what you noticed when analyzing duplicates, as well as the approach you used to eliminate them and the results you achieved.`\n",
    "\n",
    "First, you checked for missing values using the isna() method, changing them to 'unknown' using a for loop so that it leaves the default information for when there is no data for that space in the table.\n",
    "\n",
    "Then we checked for duplicate values with the duplicated() method, identifying 3. 826 explicit duplicates were identified and removed with the drop_duplicates method. However, there were still implicit duplicates, which were analyzed in the 'genre' column with unique() and nunique(), where initially there were 269 values in the list, which were related to the incorrect writing of the same genre type, and after cleaning up these values with the function created to change the wrong data to 'hiphop', there were a total of 266 values, which were then replaced.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Suas observações`\n",
    "\n",
    "`Descreva brevemente o que você reparou ao analisar duplicados, bem como a abordagem que usou para eliminá-los e os resultados que alcançou.`\n",
    "\n",
    "Inicilalmente foi verificados valores ausentes através do método isna(), sendo os mesmos alterados para 'unknown' através de um ciclo for de modo que deixa a informação padrão para quando não há dados para aquele espaço na tabela.\n",
    "\n",
    "Depois foi a verificação dos valores em duplicados com o método duplicated(), sendo identificado 3.826 duplicados explícitos que foram removidos com o método drop_duplicates, contudo, continuava a ter os duplicados implícitos que foi feita uma análise na coluna 'genre' com unique() e nunique() em que inicialmente haviam 269 valores na lista, que estavam relacionado a escrita incorreta de uma mesmo tipo gênero, e após ser feita a limpeza destes valores a função criada para alterar os dados errados para 'hiphop', ficou um total de 266 valores verificando-se então a substituição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK1es74rVujj"
   },
   "source": [
    "[Back to Index](#back)\n",
    "\n",
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WttZHXH0SqKk"
   },
   "source": [
    "## Step 3. Testing the hypothesis <a id='hypothesis'></a>\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Etapa 3. Teste da hipótese`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im936VVi_Zcu"
   },
   "source": [
    "### Hypothesis: comparison of user behavior in the two cities <a id='activity'></a>\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Hipótese: comparação do comportamento dos usuários nas duas cidades`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwt_MuaL_Zcu"
   },
   "source": [
    "The hypothesis states that there are differences in the consumption of music by users in Springfield and Shelbyville. To test the hypothesis, use data from three days of the week: Monday, Wednesday and Friday.\n",
    "\n",
    "* Group the users by city.\n",
    "* Compare the number of songs played by each group on Monday, Wednesday and Friday.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "A hipótese afirma que existem diferenças no consumo de música pelos usuários em Springfield e em Shelbyville. Para testar a hipótese, use os dados dos três dias da semana: segunda-feira (Monday), quarta-feira (Wednesday) e sexta-feira (Friday).\n",
    "\n",
    "* Agrupe os usuários por cidade.\n",
    "* Compare o número de músicas tocadas por cada grupo na segunda, quarta e sexta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dw_YMmT_Zcu"
   },
   "source": [
    "Perform each calculation separately.\n",
    "\n",
    "The first step is to evaluate user activity in each city. Don't forget the “split-apply-combine” steps we talked about earlier in the lesson. Now your goal is to group the data by city, apply the appropriate counting method during the application step and then find the number of songs played by each group, specifying the column for which you want to get the count.\n",
    "\n",
    "Here's an example of what the final result should look like:\n",
    "`df.groupby(by='....')['column'].method()` Run each calculation separately.\n",
    "\n",
    "To evaluate user activity in each city, group the data by city and find the number of songs played in each group.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Execute cada cálculo separadamente.\n",
    "\n",
    "O primeiro passo é avaliar a atividade dos usuários em cada cidade. Não se esqueça das etapas \"divisão-aplicação-combinação\" sobre as quais falamos anteriormente na lição. Agora seu objetivo é agrupar os dados por cidade, aplicar o método de contagem apropriado durante a etapa de aplicação e então encontrar o número de músicas tocadas por cada grupo, especificando a coluna para a qual você quer obter a contagem.\n",
    "\n",
    "Veja um exemplo de como o resultado final deve ser:\n",
    "`df.groupby(by='....')['column'].method()` Execute cada cálculo separadamente.\n",
    "\n",
    "Para avaliar a atividade dos usuários em cada cidade, agrupe os dados por cidade e encontre o número de músicas reproduzidas em cada grupo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0_Qs96oh_Zcu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "Shelbyville    18512\n",
       "Springfield    42741\n",
       "Name: track, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the songs played in each city / contando as músicas tocadas em cada cidade\n",
    "\n",
    "df.groupby(by = 'city')['track'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_Qx-3NewAnK"
   },
   "source": [
    "`Comment on your observations here`\n",
    "\n",
    "When we group by city and separate the number of songs listened to, you can see that Springfield basically listened to 2.3x more songs than the city of Shelbyville.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Comente sobre suas observações aqui`\n",
    "\n",
    "Ao agruparmos por cidade e separarmos o número de músicas ouvidas, pode perceber que Springfield ouviu basicamente 2.3x mais músicas que a cidade de Shelbyville."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzli3w8o_Zcu"
   },
   "source": [
    "Now let's group the data by day of the week and find the number of songs played on Monday, Wednesday and Friday. Use the same approach as before, but now we need to group the data in a different way.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Agora vamos agrupar os dados por dia da semana e encontrar a quantidade de músicas tocadas na segunda, quarta e sexta-feira. Use a mesma abordagem que antes, mas agora precisamos agrupar os dados de uma forma diferente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uZMKjiJz_Zcu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day\n",
       "Friday       21840\n",
       "Monday       21354\n",
       "Wednesday    18059\n",
       "Name: track, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the songs listened to on each of these three days / calculando as músicas escutadas em cada um desses três dias\n",
    "\n",
    "df.groupby(by = 'day')['track'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC2tNrlL_Zcu"
   },
   "source": [
    "`Comment on your observations here`\n",
    "\n",
    "With this data we can see that there is a tendency for there to be more listeners at the beginning and end of the week (Monday and Friday) while this number decreases during the week as we can see on Wednesday.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Comente sobre suas observações aqui`\n",
    "\n",
    "Com estes dados podemos perceber que existe uma tendência de haver mais ouvintes no começo e final da semana (segunda e sexta) equanto este número diminui durante a semana como podemos ver na quarta-feira."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POzs8bGa_Zcu"
   },
   "source": [
    "You've just learned how to count entries by grouping them by city or by day. And now you need to write a function that can count entries simultaneously based on both criteria.\n",
    "\n",
    "Create the `number_tracks()` function to calculate the number of songs played on a given day **and** in a given city. The function must accept two parameters:\n",
    "\n",
    "- `day`: a day of the week by which we need to filter the data. For example, `'Monday'`.\n",
    "- `city`: a city by which we need to filter the data. For example, `'Springfield'`.\n",
    "\n",
    "Inside the function, you'll apply consecutive filtering with logical indexing.\n",
    "\n",
    "First, filter the data by day and then filter the resulting table by city.\n",
    "\n",
    "After filtering the data using the two criteria, count the number of values in the 'user_id' column of the resulting table. The result of the count will represent the number of entries you want to find. Store the result in a new variable and print it.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Você acabou de aprender como contar entradas agrupando-as por cidade ou por dia. E agora você precisa escrever uma função que possa contar entradas simultaneamente com base em ambos os critérios.\n",
    "\n",
    "Crie a função `number_tracks()` para calcular o número de músicas tocadas em um determinado dia **e** em uma determinada cidade. A função deve aceitar dois parâmetros:\n",
    "\n",
    "- `day`: um dia da semana pelo qual precisamos filtrar os dados. Por exemplo, `'Monday'`.\n",
    "- `city`: uma cidade pela qual precisamos filtrar os dados. Por exemplo, `'Springfield'`.\n",
    "\n",
    "Dentro da função, você vai aplicar uma filtragem consecutiva com indexação lógica.\n",
    "\n",
    "Primeiro, filtre os dados por dia e então filtre a tabela resultante por cidade.\n",
    "\n",
    "Depois de filtrar os dados usando os dois critérios, conte o número de valores na coluna 'user_id' da tabela resultante. O resultado da contagem representará o número de entradas que você quer encontrar. Armazene o resultado em uma nova variável e imprima-o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Nz3GdQB1_Zcu"
   },
   "outputs": [],
   "source": [
    "# declare the number_tracks() function with two parameters: day= and city=. / Declare a função number_tracks() com dois parâmetros: day= e city=.\n",
    "\n",
    "    # store the rows of the DataFrame where the value in the 'day' column is equal to the day= parameter /* armazene as linhas do DataFrame em que o valor na coluna 'day' é igual ao parâmetro day=\n",
    "\n",
    "    # filter the rows where the value in the 'city' column is equal to the city= parameter / filtre as linhas em que o valor na coluna 'city' é igual ao parâmetro city=\n",
    "\n",
    "    # extract the 'user_id' column from the filtered table and apply the count() method / extraia a coluna 'user_id' da tabela filtrada e aplique o método count()\n",
    "\n",
    "    # return the number of values in the 'user_id' column / retorne o número dos valores da coluna 'user_id'\n",
    "\n",
    "def number_tracks(df, day, city):\n",
    "    choosed_day = df[df['day'] == day] \n",
    "    choosed_city = choosed_day[choosed_day['city'] == city] \n",
    "    filtered_user = choosed_city['user_id'].count()\n",
    "    return filtered_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytf7xFrFJQ2r"
   },
   "source": [
    "Call the `number_tracks()` function six times, changing the parameter values, so that you can retrieve the data for both cities for each of the three days.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Chame a função `number_tracks()` seis vezes, mudando os valores dos parâmetros, para que você possa recuperar os dados de ambas as cidades para cada um dos três dias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rJcRATNQ_Zcu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15740"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of songs played in Springfield on Monday / a quantidade de músicas tocadas em Springfield na segunda-feira\n",
    "\n",
    "number_tracks(df, 'Monday', 'Springfield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "hq_ncZ5T_Zcu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5614"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of songs played in Shelbyville on Monday / a quantidade de músicas tocadas em Shelbyville na segunda-feira\n",
    "\n",
    "number_tracks(df, 'Monday', 'Shelbyville')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_NTy2VPU_Zcu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11056"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of songs played in Springfield on Wednesday / a quantidade de músicas tocadas em Springfield na quarta-feira\n",
    "\n",
    "number_tracks(df, 'Wednesday', 'Springfield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "j2y3TAwo_Zcu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7003"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of songs played in Shelbyville on Wednesday / a quantidade de músicas tocadas em Shelbyville na quarta-feira\n",
    "\n",
    "number_tracks(df, 'Wednesday', 'Shelbyville')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vYDw5u_K_Zcu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15945"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of songs played in Springfield on Friday / a quantidade de músicas tocadas em Springfield na sexta-feira\n",
    "\n",
    "number_tracks(df, 'Friday', 'Springfield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8_yzFtW3_Zcu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5895"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number of songs played in Shelbyville on Friday / a quantidade de músicas tocadas em Shelbyville na sexta-feira\n",
    "\n",
    "number_tracks(df, 'Friday', 'Shelbyville')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EgPIHYu_Zcu"
   },
   "source": [
    "**Conclusions**\n",
    "\n",
    "`Comment on whether the third hypothesis is correct or should be rejected. Explain your reasoning.`\n",
    "\n",
    "To analyze the third hypothesis, we filtered the data using 3 days of the week to determine whether or not there is a difference in music consumption.\n",
    "\n",
    "Initially, we filtered only by city and then only by day. Finally, in order to better analyze the hypothesis, we created a code where we could analyze the day and city together and count the number of songs played.\n",
    "\n",
    "The hypothesis is therefore correct.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "**Conclusões**\n",
    "\n",
    "`Comente sobre se a terceira hipótese está correta ou deve ser rejeitada. Explique seu raciocínio.`\n",
    "\n",
    "Para analisar a terceira hipótese, foi feita uma filtragem nos dados sendo utilizados 3 dias da semana para determinar se existe ou não diferença no consumo de música.\n",
    "\n",
    "Inicialmente fizemos uma filtragem apenas pelas cidades e depois apenas pelos dias. Por último e para analisar melhor a hipótese indicada, foi criado um código onde fosse possível analisar em conjunto o dia e a cidade e contar o número de músicas tocadas.\n",
    "\n",
    "Sendo assim, a hipótese está correta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7nFQajCVw5B"
   },
   "source": [
    "[Back to Index](#back)\n",
    "\n",
    "[Voltar ao Índice](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykKQ0N65_Zcv"
   },
   "source": [
    "# Conclusions <a id='end'></a>\n",
    "\n",
    "==============================================================\n",
    "\n",
    "# Conclusões <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjUwbHb3_Zcv"
   },
   "source": [
    "`Summarize your conclusions about the hypothesis here`\n",
    "\n",
    "Based on the data provided and as indicated above, we can conclude that there is a big difference in music consumption between the cities of Springfield and Shelbyville. In order to reach this conclusion, all the “cleaning” of the data was done, which involved: adjusting the header, removing duplicates and missing values.\n",
    "\n",
    "During the analysis, we saw that there was a difference of approximately 2.3x more music consumption for the city of Springfield compared to Shelbyville. Furthermore, when we filtered the data by day and city, we found that on all the days filtered, the city of Springfield had higher consumption than Shelbyville.\n",
    "\n",
    "Once again, I emphasize that the hypothesis is valid, considering the data that was made available to us.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Resuma suas conclusões sobre a hipótese aqui`\n",
    "\n",
    "Baseado nos dados disponibilizados e como indicado anteriormente, podemos concluir que existe sim uma grande diferença no consumo de música entre as cidades de Springfield e Shelbyville. Para chegar a essa conclusão foi feita toda a \"limpeza\" dos dados que envolveu: ajustar o cabeçalho, remover duplicados e valores ausentes.\n",
    "\n",
    "Durante a análise, vimos que houve uma diferença de aproximadamente 2.3x no consumo de música a mais para a cidade de Springfield em relação Shelbyville. Além disso, quando filtrado os dados por dia e cidade, identificamos que em todos os dias filtrados a cidade de Springfield tem um consumo maior sobre Shelbyville.\n",
    "\n",
    "Reforço mais uma vez que a hipótese é válida, considerando os dados que nos foi disponibilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azLHu64yOIp7"
   },
   "source": [
    "### Important\n",
    "In real research projects, statistical hypothesis testing is more precise and quantitative. Also note that conclusions about an entire city cannot always be drawn from data from just one source.\n",
    "\n",
    "You will learn more about hypothesis testing in the sprint on statistical data analysis.\n",
    "\n",
    "==============================================================\n",
    "\n",
    "`Importante`\n",
    "\n",
    "Em projetos de pesquisas reais, o teste estatístico de hipóteses é mais preciso e quantitativo. Observe também que conclusões sobre uma cidade inteira nem sempre podem ser tiradas a partir de dados de apenas uma fonte.\n",
    "\n",
    "Você aprenderá mais sobre testes de hipóteses no sprint sobre a análise estatística de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7nFQajCVw5B"
   },
   "source": [
    "[Back to Index](#back)\n",
    "\n",
    "[Voltar ao Índice](#back)"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 502,
    "start_time": "2024-07-23T14:51:31.400Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T14:51:47.735Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-23T14:53:42.226Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-23T14:55:24.963Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-23T14:55:40.535Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-23T14:56:04.169Z"
   },
   {
    "duration": 1070,
    "start_time": "2024-07-23T14:56:49.065Z"
   },
   {
    "duration": 122,
    "start_time": "2024-07-23T14:57:20.077Z"
   },
   {
    "duration": 198,
    "start_time": "2024-07-23T14:57:47.678Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-23T14:58:09.079Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-23T14:58:14.802Z"
   },
   {
    "duration": 15,
    "start_time": "2024-07-23T14:58:55.547Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-23T14:59:36.674Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-23T15:03:07.554Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-23T15:07:44.224Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-23T15:07:56.024Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-23T15:08:00.701Z"
   },
   {
    "duration": 11,
    "start_time": "2024-07-23T15:08:24.928Z"
   },
   {
    "duration": 33,
    "start_time": "2024-07-23T15:10:05.854Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-23T15:10:31.148Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-23T15:10:48.369Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-23T15:11:20.691Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-23T15:13:06.583Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-23T15:14:30.170Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-23T15:14:37.545Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-23T15:15:07.181Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-23T15:21:40.172Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-23T15:23:23.718Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-23T15:23:28.056Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-23T15:23:43.201Z"
   },
   {
    "duration": 100,
    "start_time": "2024-07-23T15:32:34.002Z"
   },
   {
    "duration": 128,
    "start_time": "2024-07-23T15:33:27.334Z"
   },
   {
    "duration": 103,
    "start_time": "2024-07-23T15:34:01.393Z"
   },
   {
    "duration": 123,
    "start_time": "2024-07-23T15:41:05.338Z"
   },
   {
    "duration": 119,
    "start_time": "2024-07-23T15:41:18.132Z"
   },
   {
    "duration": 306,
    "start_time": "2024-07-24T08:44:10.550Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-24T08:44:26.448Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-24T08:44:32.418Z"
   },
   {
    "duration": 631,
    "start_time": "2024-07-24T08:53:32.029Z"
   },
   {
    "duration": 63,
    "start_time": "2024-07-24T08:57:49.776Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T08:58:10.637Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T08:59:12.051Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T09:00:57.441Z"
   },
   {
    "duration": 3,
    "start_time": "2024-07-24T09:02:34.661Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-24T09:04:30.616Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-24T09:04:37.807Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T09:04:42.458Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T09:11:20.450Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T09:11:24.950Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-24T09:12:30.391Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T09:12:35.839Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T09:21:28.180Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T09:22:02.310Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-24T09:23:14.536Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-24T09:24:20.932Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-24T09:25:47.254Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T09:26:59.784Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T09:27:36.920Z"
   },
   {
    "duration": 11,
    "start_time": "2024-07-24T09:27:41.633Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-24T09:33:36.802Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-24T09:33:49.689Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T09:33:55.235Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T09:33:59.994Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T09:34:03.729Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T09:34:18.245Z"
   },
   {
    "duration": 66,
    "start_time": "2024-07-24T09:34:40.049Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-24T09:36:03.218Z"
   },
   {
    "duration": 154,
    "start_time": "2024-07-24T09:36:18.617Z"
   },
   {
    "duration": 30,
    "start_time": "2024-07-24T09:36:23.646Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-24T09:36:28.270Z"
   },
   {
    "duration": 116,
    "start_time": "2024-07-24T09:37:22.734Z"
   },
   {
    "duration": 29,
    "start_time": "2024-07-24T09:37:45.592Z"
   },
   {
    "duration": 55,
    "start_time": "2024-07-24T09:38:02.336Z"
   },
   {
    "duration": 28,
    "start_time": "2024-07-24T09:38:11.017Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T09:38:55.590Z"
   },
   {
    "duration": 309,
    "start_time": "2024-07-24T12:19:40.978Z"
   },
   {
    "duration": 668,
    "start_time": "2024-07-24T12:19:46.814Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T12:19:49.729Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T12:20:11.711Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T12:23:34.521Z"
   },
   {
    "duration": 59,
    "start_time": "2024-07-24T12:33:59.398Z"
   },
   {
    "duration": 36,
    "start_time": "2024-07-24T12:34:08.601Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-24T12:38:21.652Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T12:38:32.713Z"
   },
   {
    "duration": 10,
    "start_time": "2024-07-24T12:39:00.194Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-24T13:16:58.187Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T13:17:04.582Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T13:17:16.525Z"
   },
   {
    "duration": 180,
    "start_time": "2024-07-24T13:17:17.740Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-24T13:17:19.082Z"
   },
   {
    "duration": 121,
    "start_time": "2024-07-24T13:17:21.643Z"
   },
   {
    "duration": 159,
    "start_time": "2024-07-24T13:17:25.235Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:17:26.865Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T13:17:28.430Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T13:17:29.960Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T13:17:31.123Z"
   },
   {
    "duration": 27,
    "start_time": "2024-07-24T13:17:36.395Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T13:17:38.665Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T13:20:50.930Z"
   },
   {
    "duration": 1062,
    "start_time": "2024-07-24T13:21:44.942Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-24T13:22:07.969Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:22:18.208Z"
   },
   {
    "duration": 165,
    "start_time": "2024-07-24T13:22:28.561Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:22:30.975Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T13:22:32.516Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:22:33.888Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:22:35.375Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T13:22:37.310Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:22:39.517Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-24T13:22:49.041Z"
   },
   {
    "duration": 39,
    "start_time": "2024-07-24T13:23:16.841Z"
   },
   {
    "duration": 15,
    "start_time": "2024-07-24T13:23:21.703Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T13:23:26.192Z"
   },
   {
    "duration": 72,
    "start_time": "2024-07-24T13:25:57.472Z"
   },
   {
    "duration": 127,
    "start_time": "2024-07-24T13:26:18.656Z"
   },
   {
    "duration": 127,
    "start_time": "2024-07-24T13:26:27.041Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:26:41.946Z"
   },
   {
    "duration": 122,
    "start_time": "2024-07-24T13:26:45.789Z"
   },
   {
    "duration": 157,
    "start_time": "2024-07-24T13:26:49.828Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:26:51.154Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:26:52.220Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:26:53.732Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T13:26:54.925Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T13:26:56.401Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-24T13:26:58.034Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T13:26:59.236Z"
   },
   {
    "duration": 70,
    "start_time": "2024-07-24T13:27:00.955Z"
   },
   {
    "duration": 111,
    "start_time": "2024-07-24T13:28:15.009Z"
   },
   {
    "duration": 91,
    "start_time": "2024-07-24T13:28:21.506Z"
   },
   {
    "duration": 94,
    "start_time": "2024-07-24T13:28:28.637Z"
   },
   {
    "duration": 92,
    "start_time": "2024-07-24T13:28:43.638Z"
   },
   {
    "duration": 105,
    "start_time": "2024-07-24T13:28:48.162Z"
   },
   {
    "duration": 79,
    "start_time": "2024-07-24T13:28:55.809Z"
   },
   {
    "duration": 73,
    "start_time": "2024-07-24T13:28:58.068Z"
   },
   {
    "duration": 72,
    "start_time": "2024-07-24T13:29:14.766Z"
   },
   {
    "duration": 66,
    "start_time": "2024-07-24T13:29:20.740Z"
   },
   {
    "duration": 11,
    "start_time": "2024-07-24T13:30:18.742Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T13:35:13.573Z"
   },
   {
    "duration": 42,
    "start_time": "2024-07-24T13:37:16.255Z"
   },
   {
    "duration": 32,
    "start_time": "2024-07-24T13:37:31.365Z"
   },
   {
    "duration": 33,
    "start_time": "2024-07-24T13:37:54.219Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T13:38:21.214Z"
   },
   {
    "duration": 33,
    "start_time": "2024-07-24T13:38:23.478Z"
   },
   {
    "duration": 33,
    "start_time": "2024-07-24T13:38:34.066Z"
   },
   {
    "duration": 32,
    "start_time": "2024-07-24T13:39:29.266Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-24T13:40:14.712Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T13:40:23.778Z"
   },
   {
    "duration": 12,
    "start_time": "2024-07-24T13:41:01.394Z"
   },
   {
    "duration": 9,
    "start_time": "2024-07-24T13:41:20.598Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T13:41:35.841Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T13:41:39.551Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T13:41:45.852Z"
   },
   {
    "duration": 154,
    "start_time": "2024-07-24T13:43:50.076Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T13:43:51.223Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T13:43:52.489Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T13:43:53.652Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T13:43:55.006Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-24T13:43:56.599Z"
   },
   {
    "duration": 27,
    "start_time": "2024-07-24T13:43:58.029Z"
   },
   {
    "duration": 79,
    "start_time": "2024-07-24T13:43:59.480Z"
   },
   {
    "duration": 78,
    "start_time": "2024-07-24T13:44:01.182Z"
   },
   {
    "duration": 70,
    "start_time": "2024-07-24T13:44:02.215Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T13:44:07.665Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T13:44:11.136Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T13:44:13.456Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-24T13:44:19.454Z"
   },
   {
    "duration": 457,
    "start_time": "2024-07-24T15:11:52.240Z"
   },
   {
    "duration": 193,
    "start_time": "2024-07-24T15:11:53.310Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-24T15:11:54.952Z"
   },
   {
    "duration": 124,
    "start_time": "2024-07-24T15:11:56.830Z"
   },
   {
    "duration": 119,
    "start_time": "2024-07-24T15:12:01.664Z"
   },
   {
    "duration": 152,
    "start_time": "2024-07-24T15:12:05.265Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T15:12:07.078Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T15:12:09.143Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T15:12:10.679Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T15:12:17.745Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T15:12:20.624Z"
   },
   {
    "duration": 15,
    "start_time": "2024-07-24T15:12:23.028Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T15:12:24.392Z"
   },
   {
    "duration": 74,
    "start_time": "2024-07-24T15:12:26.349Z"
   },
   {
    "duration": 80,
    "start_time": "2024-07-24T15:12:27.655Z"
   },
   {
    "duration": 67,
    "start_time": "2024-07-24T15:12:28.488Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T15:12:30.143Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T15:12:35.349Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T15:12:36.344Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-24T15:12:38.275Z"
   },
   {
    "duration": 1029,
    "start_time": "2024-07-24T15:16:02.982Z"
   },
   {
    "duration": 114,
    "start_time": "2024-07-24T15:17:15.907Z"
   },
   {
    "duration": 155,
    "start_time": "2024-07-24T15:17:25.297Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T15:17:26.873Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T15:17:28.407Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T15:17:29.875Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T15:17:31.473Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T15:17:32.942Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-24T15:17:34.432Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T15:17:35.939Z"
   },
   {
    "duration": 78,
    "start_time": "2024-07-24T15:17:37.220Z"
   },
   {
    "duration": 76,
    "start_time": "2024-07-24T15:17:38.282Z"
   },
   {
    "duration": 67,
    "start_time": "2024-07-24T15:17:39.708Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-24T15:17:40.728Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T15:17:46.594Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-24T15:17:52.399Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T15:17:55.800Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-24T15:17:56.761Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T15:17:58.384Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T15:20:12.971Z"
   },
   {
    "duration": 1107,
    "start_time": "2024-07-24T15:20:20.660Z"
   },
   {
    "duration": 243,
    "start_time": "2024-07-24T15:21:19.040Z"
   },
   {
    "duration": 83,
    "start_time": "2024-07-24T15:23:09.954Z"
   },
   {
    "duration": 81,
    "start_time": "2024-07-24T15:23:26.886Z"
   },
   {
    "duration": 84,
    "start_time": "2024-07-24T15:24:31.497Z"
   },
   {
    "duration": 42,
    "start_time": "2024-07-24T15:24:45.177Z"
   },
   {
    "duration": 66,
    "start_time": "2024-07-24T15:24:59.024Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T15:25:36.036Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T15:26:12.768Z"
   },
   {
    "duration": 67,
    "start_time": "2024-07-24T15:26:22.724Z"
   },
   {
    "duration": 73,
    "start_time": "2024-07-24T15:27:13.056Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T15:27:52.850Z"
   },
   {
    "duration": 788,
    "start_time": "2024-07-24T15:27:58.215Z"
   },
   {
    "duration": 69,
    "start_time": "2024-07-24T15:28:13.047Z"
   },
   {
    "duration": 591,
    "start_time": "2024-07-24T15:28:24.914Z"
   },
   {
    "duration": 70,
    "start_time": "2024-07-24T15:28:35.430Z"
   },
   {
    "duration": 170,
    "start_time": "2024-07-24T15:29:45.789Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T15:30:04.960Z"
   },
   {
    "duration": 23,
    "start_time": "2024-07-24T15:39:11.623Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-24T15:39:17.382Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T16:11:10.511Z"
   },
   {
    "duration": 274,
    "start_time": "2024-07-24T16:12:03.442Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-24T16:12:27.396Z"
   },
   {
    "duration": 79,
    "start_time": "2024-07-24T16:12:33.786Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T16:13:16.529Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T16:13:34.005Z"
   },
   {
    "duration": 80,
    "start_time": "2024-07-24T16:13:36.552Z"
   },
   {
    "duration": 3,
    "start_time": "2024-07-24T16:13:45.258Z"
   },
   {
    "duration": 151,
    "start_time": "2024-07-24T16:13:46.686Z"
   },
   {
    "duration": 15,
    "start_time": "2024-07-24T16:13:48.454Z"
   },
   {
    "duration": 115,
    "start_time": "2024-07-24T16:13:49.655Z"
   },
   {
    "duration": 149,
    "start_time": "2024-07-24T16:13:52.794Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T16:13:54.448Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T16:13:56.027Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T16:13:57.074Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T16:13:59.232Z"
   },
   {
    "duration": 27,
    "start_time": "2024-07-24T16:14:00.422Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-24T16:14:02.336Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T16:14:04.499Z"
   },
   {
    "duration": 70,
    "start_time": "2024-07-24T16:14:08.713Z"
   },
   {
    "duration": 74,
    "start_time": "2024-07-24T16:14:09.670Z"
   },
   {
    "duration": 69,
    "start_time": "2024-07-24T16:14:11.410Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-24T16:14:13.618Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T16:14:15.835Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-24T16:14:17.004Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T16:14:19.709Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-24T16:14:23.710Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-24T16:14:25.892Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-24T16:14:36.705Z"
   },
   {
    "duration": 81,
    "start_time": "2024-07-24T16:14:43.724Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T16:18:58.116Z"
   },
   {
    "duration": 87,
    "start_time": "2024-07-24T16:19:00.756Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-24T16:19:42.742Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-24T16:20:00.218Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-24T16:20:42.907Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-24T16:20:45.742Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-24T16:23:43.176Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-24T16:24:15.555Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T16:24:17.128Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-24T16:24:18.393Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-24T16:24:20.302Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-24T16:25:18.779Z"
   },
   {
    "duration": 451,
    "start_time": "2024-07-25T14:34:53.857Z"
   },
   {
    "duration": 194,
    "start_time": "2024-07-25T14:34:55.072Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-25T14:34:56.083Z"
   },
   {
    "duration": 132,
    "start_time": "2024-07-25T14:34:57.377Z"
   },
   {
    "duration": 154,
    "start_time": "2024-07-25T14:35:00.337Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-25T14:35:01.550Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-25T14:35:02.877Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-25T14:35:04.263Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-25T14:35:05.314Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-25T14:35:06.803Z"
   },
   {
    "duration": 32,
    "start_time": "2024-07-25T14:35:08.875Z"
   },
   {
    "duration": 76,
    "start_time": "2024-07-25T14:35:10.237Z"
   },
   {
    "duration": 90,
    "start_time": "2024-07-25T14:35:11.201Z"
   },
   {
    "duration": 78,
    "start_time": "2024-07-25T14:35:13.059Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-25T14:35:14.217Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-25T14:35:17.042Z"
   },
   {
    "duration": 31,
    "start_time": "2024-07-25T14:35:18.202Z"
   },
   {
    "duration": 20,
    "start_time": "2024-07-25T14:35:21.373Z"
   },
   {
    "duration": 1259,
    "start_time": "2024-07-25T14:35:25.009Z"
   },
   {
    "duration": 85,
    "start_time": "2024-07-25T14:35:32.037Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-25T14:35:40.160Z"
   },
   {
    "duration": 4,
    "start_time": "2024-07-25T14:36:12.967Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-25T14:36:15.330Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-25T14:36:18.566Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-25T14:36:19.813Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-25T14:36:22.261Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-25T14:36:24.317Z"
   },
   {
    "duration": 165,
    "start_time": "2024-07-25T14:36:29.795Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-25T14:36:31.834Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-25T14:36:33.716Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-25T14:36:34.868Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-25T14:36:38.053Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-25T14:36:42.825Z"
   },
   {
    "duration": 1805,
    "start_time": "2024-07-25T14:36:47.418Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-25T14:36:55.587Z"
   },
   {
    "duration": 243,
    "start_time": "2024-07-25T14:41:21.319Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-25T14:41:33.957Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-25T14:51:20.690Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-25T14:51:27.532Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-25T14:51:34.301Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-25T14:58:37.911Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-25T14:59:09.625Z"
   },
   {
    "duration": 15,
    "start_time": "2024-07-29T11:07:20.269Z"
   },
   {
    "duration": 449,
    "start_time": "2024-07-29T11:07:56.854Z"
   },
   {
    "duration": 203,
    "start_time": "2024-07-29T11:08:01.046Z"
   },
   {
    "duration": 171,
    "start_time": "2024-07-29T11:09:08.978Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-29T11:09:48.284Z"
   },
   {
    "duration": 135,
    "start_time": "2024-07-29T11:11:42.485Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-29T11:18:48.383Z"
   },
   {
    "duration": 1151,
    "start_time": "2024-07-29T11:20:17.765Z"
   },
   {
    "duration": 156,
    "start_time": "2024-07-29T11:22:51.882Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-29T11:24:32.849Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-29T11:24:50.824Z"
   },
   {
    "duration": 7,
    "start_time": "2024-07-29T11:25:31.636Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-29T11:26:10.583Z"
   },
   {
    "duration": 6,
    "start_time": "2024-07-29T11:26:34.661Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-29T11:26:41.229Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-29T11:27:15.149Z"
   },
   {
    "duration": 77,
    "start_time": "2024-07-29T11:31:54.288Z"
   },
   {
    "duration": 83,
    "start_time": "2024-07-29T11:32:17.193Z"
   },
   {
    "duration": 73,
    "start_time": "2024-07-29T11:33:02.406Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-29T11:33:38.522Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-29T11:34:40.047Z"
   },
   {
    "duration": 26,
    "start_time": "2024-07-29T11:35:15.125Z"
   },
   {
    "duration": 18,
    "start_time": "2024-07-29T11:35:57.156Z"
   },
   {
    "duration": 17,
    "start_time": "2024-07-29T11:39:26.554Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-29T11:40:46.825Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-29T11:40:50.492Z"
   },
   {
    "duration": 16,
    "start_time": "2024-07-29T11:41:19.640Z"
   },
   {
    "duration": 5,
    "start_time": "2024-07-29T11:44:44.013Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-29T11:46:39.451Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-29T11:46:39.915Z"
   },
   {
    "duration": 22,
    "start_time": "2024-07-29T11:46:40.365Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-29T11:46:40.916Z"
   },
   {
    "duration": 25,
    "start_time": "2024-07-29T11:46:41.342Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-29T11:46:41.791Z"
   },
   {
    "duration": 178,
    "start_time": "2024-07-29T11:49:32.388Z"
   },
   {
    "duration": 160,
    "start_time": "2024-07-29T11:49:43.585Z"
   },
   {
    "duration": 15,
    "start_time": "2024-07-29T11:50:04.294Z"
   },
   {
    "duration": 312,
    "start_time": "2024-08-20T14:59:22.307Z"
   },
   {
    "duration": 460,
    "start_time": "2024-08-20T14:59:30.821Z"
   },
   {
    "duration": 173,
    "start_time": "2024-08-20T14:59:31.877Z"
   },
   {
    "duration": 21,
    "start_time": "2024-08-20T14:59:32.529Z"
   },
   {
    "duration": 121,
    "start_time": "2024-08-20T14:59:34.522Z"
   },
   {
    "duration": 149,
    "start_time": "2024-08-20T15:00:17.824Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-20T15:00:31.988Z"
   },
   {
    "duration": 7,
    "start_time": "2024-08-20T15:00:42.273Z"
   },
   {
    "duration": 8,
    "start_time": "2024-08-20T15:00:50.508Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-20T15:01:06.910Z"
   },
   {
    "duration": 16,
    "start_time": "2024-08-20T15:01:31.547Z"
   },
   {
    "duration": 27,
    "start_time": "2024-08-20T15:01:41.819Z"
   },
   {
    "duration": 74,
    "start_time": "2024-08-20T15:01:50.502Z"
   },
   {
    "duration": 79,
    "start_time": "2024-08-20T15:01:59.897Z"
   },
   {
    "duration": 70,
    "start_time": "2024-08-20T15:02:04.167Z"
   },
   {
    "duration": 18,
    "start_time": "2024-08-20T15:02:24.028Z"
   },
   {
    "duration": 19,
    "start_time": "2024-08-20T15:02:32.288Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-20T15:02:42.562Z"
   },
   {
    "duration": 24,
    "start_time": "2024-08-20T15:02:48.976Z"
   },
   {
    "duration": 20,
    "start_time": "2024-08-20T15:03:02.427Z"
   },
   {
    "duration": 15,
    "start_time": "2024-08-20T15:03:24.679Z"
   },
   {
    "duration": 17,
    "start_time": "2024-08-20T15:03:33.013Z"
   },
   {
    "duration": 5,
    "start_time": "2024-08-20T15:03:41.854Z"
   },
   {
    "duration": 25,
    "start_time": "2024-08-20T15:03:47.636Z"
   },
   {
    "duration": 20,
    "start_time": "2024-08-20T15:03:47.974Z"
   },
   {
    "duration": 20,
    "start_time": "2024-08-20T15:03:48.345Z"
   },
   {
    "duration": 19,
    "start_time": "2024-08-20T15:03:48.918Z"
   },
   {
    "duration": 22,
    "start_time": "2024-08-20T15:03:50.100Z"
   },
   {
    "duration": 22,
    "start_time": "2024-08-20T15:03:51.045Z"
   }
  ],
  "colab": {
   "collapsed_sections": [
    "E0vqbgi9ay0H",
    "VUC88oWjTJw2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
